1682189998 21852057 95b9758dda7c328dc7eec12898999e9f  /cm/shared/apps/spack/0.17.3/gpu/b/etc/spack/sdsc/expanse/0.17.3/gpu/specs/gcc@10.2.0/cuda@11.2.2.sh 

#!/usr/bin/env bash

#SBATCH --job-name=cuda@11.2.2
#SBATCH --account=use300
#SBATCH --reservation=rocky8u7_testing
#SBATCH --partition=ind-gpu-shared
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=10
#SBATCH --mem=93G
#SBATCH --gpus=1
#SBATCH --time=00:30:00
#SBATCH --output=%x.o%j.%N

declare -xr LOCAL_TIME="$(date +'%Y%m%dT%H%M%S%z')"
declare -xir UNIX_TIME="$(date +'%s')"

declare -xr LOCAL_SCRATCH_DIR="/scratch/${USER}/job_${SLURM_JOB_ID}"
declare -xr TMPDIR="${LOCAL_SCRATCH_DIR}"

declare -xr SYSTEM_NAME='expanse'

declare -xr SPACK_VERSION='0.17.3'
declare -xr SPACK_INSTANCE_NAME='gpu'
declare -xr SPACK_INSTANCE_VERSION='b'
declare -xr SPACK_INSTANCE_DIR="/cm/shared/apps/spack/${SPACK_VERSION}/${SPACK_INSTANCE_NAME}/${SPACK_INSTANCE_VERSION}"

declare -xr SLURM_JOB_SCRIPT="$(scontrol show job ${SLURM_JOB_ID} | awk -F= '/Command=/{print $2}')"
declare -xr SLURM_JOB_MD5SUM="$(md5sum ${SLURM_JOB_SCRIPT})"

declare -xr SCHEDULER_MODULE='slurm/expanse/21.08.8'

echo "${UNIX_TIME} ${SLURM_JOB_ID} ${SLURM_JOB_MD5SUM} ${SLURM_JOB_DEPENDENCY}" 
echo ""

cat "${SLURM_JOB_SCRIPT}"

module purge
module load "${SCHEDULER_MODULE}"
module list
. "${SPACK_INSTANCE_DIR}/share/spack/setup-env.sh"

declare -xr SPACK_PACKAGE='cuda@11.2.2'
declare -xr SPACK_COMPILER='gcc@10.2.0'
declare -xr SPACK_VARIANTS='~dev'
declare -xr SPACK_DEPENDENCIES=''
declare -xr SPACK_SPEC="${SPACK_PACKAGE} % ${SPACK_COMPILER} ${SPACK_VARIANTS} ${SPACK_DEPENDENCIES}"

printenv

spack config get compilers  
spack config get config  
spack config get mirrors
spack config get modules
spack config get packages
spack config get repos
spack config get upstreams

time -p spack spec --long --namespaces --types "${SPACK_SPEC}"
if [[ "${?}" -ne 0 ]]; then
  echo 'ERROR: spack concretization failed.'
  exit 1
fi

time -p spack install --jobs "${SLURM_CPUS_PER_TASK}" --fail-fast --yes-to-all "${SPACK_SPEC}"
if [[ "${?}" -ne 0 ]]; then
  echo 'ERROR: spack install failed.'
  exit 1
fi

#spack module lmod refresh --delete-tree -y

sbatch --dependency="afterok:${SLURM_JOB_ID}" 'cudnn@8.1.1.33-11.2.sh'

sleep 30

Currently Loaded Modules:
  1) slurm/expanse/21.08.8

 

LD_LIBRARY_PATH=/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64
LS_COLORS=rs=0:di=38;5;33:ln=38;5;51:mh=00:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=01;05;37;41:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;40:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.zst=38;5;9:*.tzst=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.wim=38;5;9:*.swm=38;5;9:*.dwm=38;5;9:*.esd=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.mjpg=38;5;13:*.mjpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.m4a=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.oga=38;5;45:*.opus=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
SRUN_DEBUG=3
SLURM_STEP_ID=0
LOCAL_SCRATCH_DIR=/scratch/spack_gpu/job_21852057
SLURM_STEP_GPUS=1
SLURM_NODEID=0
SLURM_TASK_PID=1405689
__LMOD_REF_COUNT_PATH=/cm/shared/apps/slurm/current/sbin:1;/cm/shared/apps/slurm/current/bin:1;/home/spack_gpu/.local/bin:2;/home/spack_gpu/bin:2;/usr/local/bin:1;/usr/bin:1;/usr/local/sbin:1;/usr/sbin:1
_ModuleTable002_=L2NtL3NoYXJlZC9hcHBzL3hzZWRlL21vZHVsZWZpbGVzIiwiL2V0Yy9tb2R1bGVmaWxlcyIsIi91c3Ivc2hhcmUvbW9kdWxlZmlsZXMiLCIvdXNyL3NoYXJlL01vZHVsZXMvbW9kdWxlZmlsZXMiLCIvY20vc2hhcmVkL21vZHVsZWZpbGVzIix9LFsic3lzdGVtQmFzZU1QQVRIIl09Ii9jbS9sb2NhbC9tb2R1bGVmaWxlczovY20vc2hhcmVkL2FwcHMvYWNjZXNzL21vZHVsZWZpbGVzOi9jbS9zaGFyZWQvYXBwcy94c2VkZS9tb2R1bGVmaWxlczovY20vc2hhcmVkL21vZHVsZWZpbGVzOi9ldGMvbW9kdWxlZmlsZXM6L3Vzci9zaGFyZS9tb2R1bGVmaWxlczovdXNyL3NoYXJlL01vZHVsZXMvbW9kdWxlZmlsZXMiLH0=
SSH_CONNECTION=198.202.100.14 35298 198.202.100.14 22
SPACK_PYTHON=/usr/bin/python3
SLURM_PRIO_PROCESS=0
SLURM_CPU_BIND_VERBOSE=quiet
LANG=en_US.UTF-8
SLURM_SUBMIT_DIR=/cm/shared/apps/spack/0.17.3/gpu/b/etc/spack/sdsc/expanse/0.17.3/gpu/specs/gcc@10.2.0
HISTCONTROL=ignoredups
HOSTNAME=exp-15-57
LMOD_SYSTEM_DEFAULT_MODULES=DefaultModules
OLDPWD=/cm/shared/apps/spack/0.17.3/gpu/b/etc/spack/sdsc/expanse/0.17.3/gpu/specs
__LMOD_REF_COUNT__LMFILES_=/cm/shared/modulefiles/slurm/expanse/21.08.8:1
SLURM_CPUS_PER_TASK=10
SLURM_STEPID=0
SLURM_SRUN_COMM_HOST=10.21.0.20
SPACK_DEPENDENCIES=
SLURM_DISTRIBUTION=cyclic
ENVIRONMENT=BATCH
SPACK_VERSION=0.17.3
ROCR_VISIBLE_DEVICES=0
SLURM_PROCID=0
SPACK_INSTANCE_VERSION=b
SLURM_JOB_GID=11491
SPACK_VARIANTS=~dev
SPACK_INSTANCE_DIR=/cm/shared/apps/spack/0.17.3/gpu/b
__LMOD_REF_COUNT_LD_LIBRARY_PATH=/cm/shared/apps/slurm/current/lib64/slurm:1;/cm/shared/apps/slurm/current/lib64:1
SLURM_CPU_BIND=quiet,mask_cpu:0x5555500000
SLURM_JOB_SCRIPT=/cm/shared/apps/spack/0.17.3/gpu/b/etc/spack/sdsc/expanse/0.17.3/gpu/specs/gcc@10.2.0/cuda@11.2.2.sh
SLURMD_NODENAME=exp-15-57
SLURM_TASKS_PER_NODE=1
S_COLORS=auto
which_declare=declare -f
SPACK_COMPILER=gcc@10.2.0
SLURM_JOB_RESERVATION=rocky8u7_testing
XDG_SESSION_ID=80047
USER=spack_gpu
SLURM_NNODES=1
SLURM_LAUNCH_NODE_IPADDR=10.21.0.20
SLURM_STEP_TASKS_PER_NODE=1
SLURM_NTASKS_PER_NODE=1
__LMOD_REF_COUNT_MODULEPATH=/cm/local/modulefiles:1;/cm/shared/apps/access/modulefiles:1;/cm/shared/apps/xsede/modulefiles:1;/etc/modulefiles:1;/usr/share/modulefiles:1;/usr/share/Modules/modulefiles:1;/cm/shared/modulefiles:1
__LMOD_REF_COUNT_LOADEDMODULES=slurm/expanse/21.08.8:1
SLURM_GPUS=1
PWD=/cm/shared/apps/spack/0.17.3/gpu/b/etc/spack/sdsc/expanse/0.17.3/gpu/specs/gcc@10.2.0
ENABLE_LMOD=1
SLURM_JOB_NODELIST=exp-15-57
HOME=/home/spack_gpu
SLURM_CLUSTER_NAME=expanse
LMOD_COLORIZE=yes
LOCAL_TIME=20230422T115958-0700
SLURM_NODELIST=exp-15-57
SLURM_GPUS_ON_NODE=1
SSH_CLIENT=198.202.100.14 35298 22
LMOD_VERSION=8.2.4
CPATH=/cm/shared/apps/slurm/current/include
SLURM_NTASKS=1
LMOD_SETTARG_CMD=:
SLURM_JOB_CPUS_PER_NODE=10
BASH_ENV=/usr/share/lmod/lmod/init/bash
SLURM_TOPOLOGY_ADDR=exp-15-57
SLURM_WORKING_CLUSTER=expanse:mgr1:6817:9472:109
SLURM_JOB_MD5SUM=95b9758dda7c328dc7eec12898999e9f  /cm/shared/apps/spack/0.17.3/gpu/b/etc/spack/sdsc/expanse/0.17.3/gpu/specs/gcc@10.2.0/cuda@11.2.2.sh
SPACK_PACKAGE=cuda@11.2.2
__LMOD_REF_COUNT_LIBRARY_PATH=/cm/shared/apps/slurm/current/lib64/slurm:1;/cm/shared/apps/slurm/current/lib64:1
SLURM_STEP_NODELIST=exp-15-57
SLURM_JOB_NAME=cuda@11.2.2
SLURM_SRUN_COMM_PORT=43281
TMPDIR=/scratch/spack_gpu/job_21852057
LIBRARY_PATH=/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64
SLURM_JOB_GPUS=0
LMOD_sys=Linux
SLURM_JOBID=21852057
SYSTEM_NAME=expanse
_ModuleTable001_=X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXt9LG1UPXtbInNsdXJtL2V4cGFuc2UiXT17WyJmbiJdPSIvY20vc2hhcmVkL21vZHVsZWZpbGVzL3NsdXJtL2V4cGFuc2UvMjEuMDguOCIsWyJmdWxsTmFtZSJdPSJzbHVybS9leHBhbnNlLzIxLjA4LjgiLFsibG9hZE9yZGVyIl09MSxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJzbHVybS9leHBhbnNlLzIxLjA4LjgiLH0sfSxtcGF0aEE9eyIvY20vbG9jYWwvbW9kdWxlZmlsZXMiLCIvY20vc2hhcmVkL2FwcHMvYWNjZXNzL21vZHVsZWZpbGVzIiwi
SLURM_CONF=/cm/shared/apps/slurm/var/etc/expanse/slurm.conf
LOADEDMODULES=slurm/expanse/21.08.8
__LMOD_REF_COUNT_MANPATH=/cm/shared/apps/slurm/current/man:3;/usr/share/lmod/lmod/share/man:1;/usr/local/share/man:2;/usr/share/man:2;/cm/local/apps/environment-modules/current/share/man:2
_ModuleTable003_=dXJtPXtbImZuIl09Ii9jbS9sb2NhbC9tb2R1bGVmaWxlcy9zbHVybS9leHBhbnNlLzIxLjA4LjgiLFsiZnVsbE5hbWUiXT0ic2x1cm0vZXhwYW5zZS8yMS4wOC44IixbImxvYWRPcmRlciJdPTMscHJvcFQ9e30sWyJzdGFja0RlcHRoIl09MixbInN0YXR1cyJdPSJhY3RpdmUiLFsidXNlck5hbWUiXT0ic2x1cm0iLH0sfSxtcGF0aEE9eyIvY20vc2hhcmVkL2FwcHMvc3BhY2svY3B1L2xtb2QvbGludXgtY2VudG9zOC14ODZfNjQvQ29yZSIsIi9jbS9sb2NhbC9tb2R1bGVmaWxlcyIsIi9jbS9zaGFyZWQvYXBwcy9hY2Nlc3MvbW9kdWxlZmlsZXMiLCIvY20vc2hhcmVkL2FwcHMveHNlZGUvbW9kdWxlZmlsZXMiLCIvZXRjL21vZHVsZWZpbGVzIiwiL3Vzci9zaGFyZS9tb2R1bGVm
SLURM_NODE_ALIASES=(null)
LMOD_ROOT=/usr/share/lmod
SLURM_JOB_QOS=ind-gpu-shared-normal
SLURM_TOPOLOGY_ADDR_PATTERN=node
SSH_TTY=/dev/pts/428
MAIL=/var/spool/mail/spack_gpu
SLURM_CPUS_ON_NODE=10
LMOD_arch=x86_64
SLURM_JOB_NUM_NODES=1
__Init_Default_Modules=1
CMD_WLM_CLUSTER_NAME=expanse
SLURM_MEM_PER_NODE=95232
SPACK_ROOT=/cm/shared/apps/spack/0.17.3/gpu/b
TERM=xterm-256color
SHELL=/bin/bash
_ModuleTable_Sz_=2
SLURM_JOB_UID=527835
__LMOD_REF_COUNT_CPATH=/cm/shared/apps/slurm/current/include:1
SLURM_JOB_PARTITION=ind-gpu-shared
SLURM_PTY_WIN_ROW=24
SLURM_CPU_BIND_LIST=0x5555500000
SPACK_INSTANCE_NAME=gpu
SLURM_JOB_USER=spack_gpu
CUDA_VISIBLE_DEVICES=0
SLURM_PTY_WIN_COL=80
SLURM_NPROCS=1
SHLVL=3
SLURM_SUBMIT_HOST=exp-15-57
UNIX_TIME=1682189998
SLURM_JOB_ACCOUNT=use300
MANPATH=/cm/shared/apps/slurm/current/man:/usr/share/lmod/lmod/share/man:/usr/local/share/man:/usr/share/man:/cm/local/apps/environment-modules/current/share/man
LMOD_PREPEND_BLOCK=normal
SLURM_STEP_LAUNCHER_PORT=43281
MODULEPATH=/cm/local/modulefiles:/cm/shared/apps/access/modulefiles:/cm/shared/apps/xsede/modulefiles:/etc/modulefiles:/usr/share/modulefiles:/usr/share/Modules/modulefiles:/cm/shared/modulefiles
SLURM_PTY_PORT=41821
SLURM_GTIDS=0
LOGNAME=spack_gpu
DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/527835/bus
XDG_RUNTIME_DIR=/run/user/527835
MODULEPATH_ROOT=/usr/share/modulefiles
PATH=/cm/shared/apps/spack/0.17.3/gpu/b/bin:/cm/shared/apps/slurm/current/sbin:/cm/shared/apps/slurm/current/bin:/home/spack_gpu/.local/bin:/home/spack_gpu/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
SLURM_JOB_ID=21852057
_LMFILES_=/cm/shared/modulefiles/slurm/expanse/21.08.8
SLURM_CPU_BIND_TYPE=mask_cpu:
DEBUGINFOD_URLS=https://debuginfod.centos.org/ 
SLURM_STEP_NUM_TASKS=1
SCHEDULER_MODULE=slurm/expanse/21.08.8
MODULESHOME=/usr/share/lmod/lmod
LMOD_SETTARG_FULL_SUPPORT=no
HISTSIZE=-1
LMOD_PKG=/usr/share/lmod/lmod
SLURM_STEP_NUM_NODES=1
SPACK_SPEC=cuda@11.2.2 % gcc@10.2.0 ~dev 
LMOD_CMD=/usr/share/lmod/lmod/libexec/lmod
SLURM_LOCALID=0
GPU_DEVICE_ORDINAL=0
LESSOPEN=||/usr/bin/lesspipe.sh %s
LMOD_FULL_SETTARG_SUPPORT=no
LMOD_DIR=/usr/share/lmod/lmod/libexec
BASH_FUNC_which%%=() {  ( alias;
 eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot $@
}
BASH_FUNC_module%%=() {  eval $($LMOD_CMD bash "$@") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)
}
BASH_FUNC_spack%%=() {  : this is a shell function from: /cm/shared/apps/spack/0.17.3/gpu/b/share/spack/setup-env.sh;
 : the real spack script is here: /cm/shared/apps/spack/0.17.3/gpu/b/bin/spack;
 _spack_shell_wrapper "$@";
 return $?
}
BASH_FUNC__spack_shell_wrapper%%=() {  for var in LD_LIBRARY_PATH DYLD_LIBRARY_PATH DYLD_FALLBACK_LIBRARY_PATH;
 do
 eval "if [ -n \"\${${var}-}\" ]; then export SPACK_$var=\${${var}}; fi";
 done;
 if [ -n "${ZSH_VERSION:-}" ]; then
 emulate -L sh;
 fi;
 _sp_flags="";
 while [ ! -z ${1+x} ] && [ "${1#-}" != "${1}" ]; do
 _sp_flags="$_sp_flags $1";
 shift;
 done;
 if [ -n "$_sp_flags" ] && [ "${_sp_flags#*h}" != "${_sp_flags}" ] || [ "${_sp_flags#*V}" != "${_sp_flags}" ]; then
 command spack $_sp_flags "$@";
 return;
 fi;
 _sp_subcommand="";
 if [ ! -z ${1+x} ]; then
 _sp_subcommand="$1";
 shift;
 fi;
 case $_sp_subcommand in 
 "cd")
 _sp_arg="";
 if [ -n "$1" ]; then
 _sp_arg="$1";
 shift;
 fi;
 if [ "$_sp_arg" = "-h" ] || [ "$_sp_arg" = "--help" ]; then
 command spack cd -h;
 else
 LOC="$(spack location $_sp_arg "$@")";
 if [ -d "$LOC" ]; then
 cd "$LOC";
 else
 return 1;
 fi;
 fi;
 return
 ;;
 "env")
 _sp_arg="";
 if [ -n "$1" ]; then
 _sp_arg="$1";
 shift;
 fi;
 if [ "$_sp_arg" = "-h" ] || [ "$_sp_arg" = "--help" ]; then
 command spack env -h;
 else
 case $_sp_arg in 
 activate)
 _a=" $@";
 if [ -z ${1+x} ] || [ "${_a#* --sh}" != "$_a" ] || [ "${_a#* --csh}" != "$_a" ] || [ "${_a#* -h}" != "$_a" ] || [ "${_a#* --help}" != "$_a" ]; then
 command spack env activate "$@";
 else
 stdout="$(command spack $_sp_flags env activate --sh "$@")" || return;
 eval "$stdout";
 fi
 ;;
 deactivate)
 _a=" $@";
 if [ "${_a#* --sh}" != "$_a" ] || [ "${_a#* --csh}" != "$_a" ]; then
 command spack env deactivate "$@";
 else
 if [ -n "$*" ]; then
 command spack env deactivate -h;
 else
 stdout="$(command spack $_sp_flags env deactivate --sh)" || return;
 eval "$stdout";
 fi;
 fi
 ;;
 *)
 command spack env $_sp_arg "$@"
 ;;
 esac;
 fi;
 return
 ;;
 "load" | "unload")
 _a=" $@";
 if [ "${_a#* --sh}" != "$_a" ] || [ "${_a#* --csh}" != "$_a" ] || [ "${_a#* -h}" != "$_a" ] || [ "${_a#* --list}" != "$_a" ] || [ "${_a#* --help}" != "$_a" ]; then
 command spack $_sp_flags $_sp_subcommand "$@";
 else
 stdout="$(command spack $_sp_flags $_sp_subcommand --sh "$@")" || return;
 eval "$stdout";
 fi
 ;;
 *)
 command spack $_sp_flags $_sp_subcommand "$@"
 ;;
 esac
}
BASH_FUNC_ml%%=() {  eval $($LMOD_DIR/ml_cmd "$@")
}
_=/usr/bin/printenv
compilers:
- compiler:
    spec: gcc@8.5.0
    paths:
      cc: /usr/bin/gcc
      cxx: /usr/bin/g++
      f77: /usr/bin/gfortran
      fc: /usr/bin/gfortran
    flags:
      cflags: -O2 -march=native
      cxxflags: -O2 -march=native
      fflags: -O2 -march=native
    operating_system: rocky8
    target: x86_64
    modules: []
    environment: {}
    extra_rpaths: []
- compiler:
    spec: gcc@10.2.0
    paths:
      cc: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gcc
      cxx: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/g++
      f77: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gfortran
      fc: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gfortran
    flags:
      cflags: -O2 -march=native
      cxxflags: -O2 -march=native
      fflags: -O2 -march=native
    operating_system: rocky8
    target: x86_64
    modules: []
    environment: {}
    extra_rpaths: []
config:
  install_tree:
    root: $spack/opt/spack
    projections:
      all: ${ARCHITECTURE}/${COMPILERNAME}-${COMPILERVER}/${PACKAGE}-${VERSION}-${HASH}
  template_dirs:
  - $spack/share/spack/templates

  # Temporary locations Spack can try to use for builds.
  #
  # Recommended options are given below.
  #
  # Builds can be faster in temporary directories on some (e.g., HPC) systems.
  # Specifying `$tempdir` will ensure use of the default temporary directory
  # (i.e., ``$TMP` or ``$TMPDIR``).
  #
  # Another option that prevents conflicts and potential permission issues is
  # to specify `$user_cache_path/stage`, which ensures each user builds in their
  # home directory.
  #
  # A more traditional path uses the value of `$spack/var/spack/stage`, which
  # builds directly inside Spack's instance without staging them in a
  # temporary space.  Problems with specifying a path inside a Spack instance
  # are that it precludes its use as a system package and its ability to be
  # pip installable.
  #
  # In any case, if the username is not already in the path, Spack will append
  # the value of `$user` in an attempt to avoid potential conflicts between
  # users in shared temporary spaces.
  #
  # The build stage can be purged with `spack clean --stage` and
  # `spack clean -a`, so it is important that the specified directory uniquely
  # identifies Spack staging to avoid accidentally wiping out non-Spack work.
  build_stage:
  - $tempdir/$user/spack-stage
  - $user_cache_path/stage
  # - $spack/var/spack/stage

  # Directory in which to run tests and store test results.
  # Tests will be stored in directories named by date/time and package
  # name/hash.
  test_stage: $user_cache_path/test
  source_cache: $spack/var/spack/cache
  misc_cache: $user_cache_path/cache
  connect_timeout: 10
  verify_ssl: true
  suppress_gpg_warnings: false
  install_missing_compilers: false
  checksum: true
  deprecated: false
  dirty: false
  build_language: C
  locks: true
  url_fetch_method: urllib
  ccache: false
  concretizer: clingo
  db_lock_timeout: 3
  package_lock_timeout: null
  shared_linking: rpath
  allow_sgid: true
  terminal_title: false
  debug: false
  build_jobs: 10
mirrors:
  spack-public: https://mirror.spack.io
modules:
  default:
    'enable:':
    - lmod
    lmod:
      core_compilers:
      - gcc@8.5.0
      hierarchy:
      - mpi
      hash_length: 0
      blacklist_implicits: true
      naming_scheme: '{name}/{version}/{hash:7}'
      projections:
        all: '{name}/{version}/{hash:7}'
      all:
        suffixes:
          +openmp: omp
          threads=openmp: omp
          +ipl64: i64
      cuda:
        environment:
          prepend_path:
            PATH: /cm/local/apps/cuda/libs/current/bin
            LD_LIBRARY_PATH: /cm/local/apps/cuda/libs/current/lib64
          set:
            CUDATOOLKIT_HOME: /cm/local/apps/cuda
      intel:
        environment:
          set:
            INTEL_LICENSE_FILE: 40000@elprado.sdsc.edu:40200@elprado.sdsc.edu
      petsc:
        suffixes:
          +complex: cmplx
      slepc:
        suffixes:
          ^petsc +complex: cmplx
      ^cuda:
        autoload: direct
      ^python:
        autoload: direct
      ^ucx:
        autoload: direct
  prefix_inspections:
    lib:
    - LD_LIBRARY_PATH
    lib64:
    - LD_LIBRARY_PATH
    bin:
    - PATH
    man:
    - MANPATH
    share/man:
    - MANPATH
    share/aclocal:
    - ACLOCAL_PATH
    lib/pkgconfig:
    - PKG_CONFIG_PATH
    lib64/pkgconfig:
    - PKG_CONFIG_PATH
    share/pkgconfig:
    - PKG_CONFIG_PATH
    ? ''
    : - CMAKE_PREFIX_PATH

  # These are configurations for the module set named "default"
packages:
  lmod:
    externals:
    - spec: lmod@8.2.4
      prefix: /usr
    buildable: false
  lustre:
    externals:
    - spec: lustre@2.15.2
      prefix: /usr
    buildable: false
  openssl:
    externals:
    - spec: openssl@1.1.1k
      prefix: /usr
    buildable: false
  rdma-core:
    externals:
    - spec: rdma-core@43.0
      prefix: /usr
    buildable: false
  slurm:
    externals:
    - spec: slurm@21.08.8
      prefix: /cm/shared/apps/slurm/21.08.8
    buildable: false
  librsvg:
    externals:
    - spec: librsvg@2.42.7
      prefix: /usr
    buildable: false
  ghostscript:
    externals:
    - spec: ghostscript@9.27
      prefix: /usr
    buildable: false
  gaussian:
    permissions:
      read: group
      group: gaussian
  vasp6:
    permissions:
      read: group
      group: vasp-6
  all:
    compiler: [gcc, intel, pgi, clang, xl, nag, fj, aocc]
    providers:
      awk: [gawk]
      blas: [openblas, amdblis]
      D: [ldc]
      daal: [intel-daal]
      elf: [elfutils]
      fftw-api: [fftw, amdfftw]
      flame: [libflame, amdlibflame]
      fuse: [libfuse]
      gl: [mesa+opengl, mesa18, opengl]
      glu: [mesa-glu, openglu]
      glx: [mesa+glx, mesa18+glx, opengl]
      golang: [gcc]
      iconv: [libiconv]
      ipp: [intel-ipp]
      java: [openjdk, jdk, ibm-java]
      jpeg: [libjpeg-turbo, libjpeg]
      lapack: [openblas, amdlibflame]
      lua-lang: [lua, lua-luajit]
      mariadb-client: [mariadb-c-client, mariadb]
      mkl: [intel-mkl]
      mpe: [mpe2]
      mpi: [openmpi, mpich]
      mysql-client: [mysql, mariadb-c-client]
      opencl: [pocl]
      onedal: [intel-oneapi-dal]
      osmesa: [mesa+osmesa, mesa18+osmesa]
      pbs: [openpbs, torque]
      pil: [py-pillow]
      pkgconfig: [pkgconf, pkg-config]
      rpc: [libtirpc]
      scalapack: [netlib-scalapack, amdscalapack]
      sycl: [hipsycl]
      szip: [libaec, libszip]
      tbb: [intel-tbb]
      unwind: [libunwind]
      uuid: [util-linux-uuid, libuuid]
      xxd: [xxd-standalone, vim]
      yacc: [bison, byacc]
      ziglang: [zig]
    permissions:
      read: world
      write: user
repos:
- $spack/var/spack/repos/sdsc
- $spack/var/spack/repos/builtin
upstreams: {}
Input spec
--------------------------------
[    ]  .cuda@11.2.2%gcc@10.2.0~dev

Concretized
--------------------------------
blza2ps  [    ]  builtin.cuda@11.2.2%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~dev arch=linux-rocky8-cascadelake
2q4yola  [bl  ]      ^builtin.libxml2@2.9.12%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~python arch=linux-rocky8-cascadelake
5a3xt3s  [bl  ]          ^builtin.libiconv@1.16%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native"  libs=shared,static arch=linux-rocky8-cascadelake
fnvohig  [b   ]          ^builtin.pkgconf@1.8.0%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native"  arch=linux-rocky8-cascadelake
5xho2dj  [bl  ]          ^builtin.xz@5.2.5%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~pic libs=shared,static arch=linux-rocky8-cascadelake
2c5fvip  [bl  ]          ^builtin.zlib@1.2.11%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" +optimize+pic+shared arch=linux-rocky8-cascadelake

real 2.13
user 1.19
sys 0.15
==> Installing libiconv-1.16-5a3xt3stjvynuygepnoy3fwkc4p524af
==> No binary for libiconv-1.16-5a3xt3stjvynuygepnoy3fwkc4p524af found: installing from source
==> Warning: Expected user 527835 to own /scratch/spack_gpu, but it is owned by 0
==> Using cached archive: /cm/shared/apps/spack/0.17.3/gpu/b/var/spack/cache/_source-cache/archive/e6/e6a1b1b589654277ee790cce3734f07876ac4ccfaecbee8afa0b649cf529cc04.tar.gz
==> No patches needed for libiconv
==> libiconv: Executing phase: 'autoreconf'
==> libiconv: Executing phase: 'configure'
==> libiconv: Executing phase: 'build'
==> libiconv: Executing phase: 'install'
==> libiconv: Successfully installed libiconv-1.16-5a3xt3stjvynuygepnoy3fwkc4p524af
  Fetch: 0.02s.  Build: 21.43s.  Total: 21.45s.
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/libiconv-1.16-5a3xt3stjvynuygepnoy3fwkc4p524af
==> Installing pkgconf-1.8.0-fnvohigop5ofhxljpwd3zmpe5xkmhj7c
==> No binary for pkgconf-1.8.0-fnvohigop5ofhxljpwd3zmpe5xkmhj7c found: installing from source
==> Using cached archive: /cm/shared/apps/spack/0.17.3/gpu/b/var/spack/cache/_source-cache/archive/ef/ef9c7e61822b7cb8356e6e9e1dca58d9556f3200d78acab35e4347e9d4c2bbaf.tar.xz
==> No patches needed for pkgconf
==> pkgconf: Executing phase: 'autoreconf'
==> pkgconf: Executing phase: 'configure'
==> pkgconf: Executing phase: 'build'
==> pkgconf: Executing phase: 'install'
==> pkgconf: Successfully installed pkgconf-1.8.0-fnvohigop5ofhxljpwd3zmpe5xkmhj7c
  Fetch: 0.00s.  Build: 4.14s.  Total: 4.15s.
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/pkgconf-1.8.0-fnvohigop5ofhxljpwd3zmpe5xkmhj7c
==> Installing xz-5.2.5-5xho2djgxmtrybtbc7q5q2yi5juesbqu
==> No binary for xz-5.2.5-5xho2djgxmtrybtbc7q5q2yi5juesbqu found: installing from source
==> Using cached archive: /cm/shared/apps/spack/0.17.3/gpu/b/var/spack/cache/_source-cache/archive/51/5117f930900b341493827d63aa910ff5e011e0b994197c3b71c08a20228a42df.tar.bz2
==> No patches needed for xz
==> xz: Executing phase: 'autoreconf'
==> xz: Executing phase: 'configure'
==> xz: Executing phase: 'build'
==> xz: Executing phase: 'install'
==> xz: Successfully installed xz-5.2.5-5xho2djgxmtrybtbc7q5q2yi5juesbqu
  Fetch: 0.01s.  Build: 13.88s.  Total: 13.89s.
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/xz-5.2.5-5xho2djgxmtrybtbc7q5q2yi5juesbqu
==> Installing zlib-1.2.11-2c5fvipdd5evacdfivwheqdtijr5om5z
==> No binary for zlib-1.2.11-2c5fvipdd5evacdfivwheqdtijr5om5z found: installing from source
==> Using cached archive: /cm/shared/apps/spack/0.17.3/gpu/b/var/spack/cache/_source-cache/archive/c3/c3e5e9fdd5004dcb542feda5ee4f0ff0744628baf8ed2dd5d66f8ca1197cb1a1.tar.gz
==> No patches needed for zlib
==> zlib: Executing phase: 'install'
==> zlib: Successfully installed zlib-1.2.11-2c5fvipdd5evacdfivwheqdtijr5om5z
  Fetch: 0.01s.  Build: 2.19s.  Total: 2.19s.
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/zlib-1.2.11-2c5fvipdd5evacdfivwheqdtijr5om5z
==> Installing libxml2-2.9.12-2q4yola2ylijts5vlbv353pptxgmu5xs
==> No binary for libxml2-2.9.12-2q4yola2ylijts5vlbv353pptxgmu5xs found: installing from source
==> Using cached archive: /cm/shared/apps/spack/0.17.3/gpu/b/var/spack/cache/_source-cache/archive/c8/c8d6681e38c56f172892c85ddc0852e1fd4b53b4209e7f4ebf17f7e2eae71d92.tar.gz
==> Using cached archive: /cm/shared/apps/spack/0.17.3/gpu/b/var/spack/cache/_source-cache/archive/96/96151685cec997e1f9f3387e3626d61e6284d4d6e66e0e440c209286c03e9cc7.tar.gz
==> Moving resource stage
	source: /scratch/spack_gpu/job_21852057/spack-stage/resource-xmlts-2q4yola2ylijts5vlbv353pptxgmu5xs/spack-src/
	destination: /scratch/spack_gpu/job_21852057/spack-stage/spack-stage-libxml2-2.9.12-2q4yola2ylijts5vlbv353pptxgmu5xs/spack-src/xmlconf
==> Ran patch() for libxml2
==> libxml2: Executing phase: 'autoreconf'
==> libxml2: Executing phase: 'configure'
==> libxml2: Executing phase: 'build'
==> libxml2: Executing phase: 'install'
==> libxml2: Successfully installed libxml2-2.9.12-2q4yola2ylijts5vlbv353pptxgmu5xs
  Fetch: 0.03s.  Build: 20.72s.  Total: 20.75s.
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/libxml2-2.9.12-2q4yola2ylijts5vlbv353pptxgmu5xs
==> Installing cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx
==> No binary for cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx found: installing from source
==> Fetching https://mirror.spack.io/_source-cache/archive/0a/0a2e477224af7f6003b49edfd2bfee07667a8148fe3627cfd2765f6ad72fa19d
==> No patches needed for cuda
==> cuda: Executing phase: 'install'
==> cuda: Successfully installed cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx
  Fetch: 1m 22.57s.  Build: 1m 29.08s.  Total: 2m 51.65s.
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx
real 247.58
user 200.34
sys 86.82
Submitted batch job 21852101
