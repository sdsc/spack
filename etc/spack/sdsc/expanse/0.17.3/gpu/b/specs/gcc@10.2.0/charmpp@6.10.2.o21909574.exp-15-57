1682365205 21909574 76d63265f5454cbe135e9d01efd29c23  /home/spack_gpu/software/namd/charmpp@6.10.2.sh 

#!/usr/bin/env bash

#SBATCH --job-name=charmpp@6.10.2
#SBATCH --account=use300
#SBATCH --reservation=rocky8u7_testing
#SBATCH --partition=ind-gpu-shared
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=10
#SBATCH --mem=93G
#SBATCH --gpus=1
#SBATCH --time=48:00:00
#SBATCH --output=%x.o%j.%N

declare -xr LOCAL_TIME="$(date +'%Y%m%dT%H%M%S%z')"
declare -xir UNIX_TIME="$(date +'%s')"

declare -xr LOCAL_SCRATCH_DIR="/scratch/${USER}/job_${SLURM_JOB_ID}"
declare -xr TMPDIR="${LOCAL_SCRATCH_DIR}"

declare -xr SYSTEM_NAME='expanse'

declare -xr SPACK_VERSION='0.17.3'
declare -xr SPACK_INSTANCE_NAME='gpu'
declare -xr SPACK_INSTANCE_VERSION='b'
declare -xr SPACK_INSTANCE_DIR="/cm/shared/apps/spack/${SPACK_VERSION}/${SPACK_INSTANCE_NAME}/${SPACK_INSTANCE_VERSION}"

declare -xr SLURM_JOB_SCRIPT="$(scontrol show job ${SLURM_JOB_ID} | awk -F= '/Command=/{print $2}')"
declare -xr SLURM_JOB_MD5SUM="$(md5sum ${SLURM_JOB_SCRIPT})"

declare -xr SCHEDULER_MODULE='slurm'
declare -xr COMPILER_MODULE='gcc/10.2.0'
declare -xr CUDA_MODULE='cuda/11.2.2'

echo "${UNIX_TIME} ${SLURM_JOB_ID} ${SLURM_JOB_MD5SUM} ${SLURM_JOB_DEPENDENCY}" 
echo ""

cat "${SLURM_JOB_SCRIPT}"

module purge
module load "${SCHEDULER_MODULE}"
. "${SPACK_INSTANCE_DIR}/share/spack/setup-env.sh"
module use "${SPACK_ROOT}/share/spack/lmod/linux-rocky8-x86_64/Core"
module load "${COMPILER_MODULE}"
module load "${CUDA_MODULE}"
module list

# unsatisfiable, conflicts are:
#  A conflict was triggered
#  condition(322)
#  condition(331)
#  condition(337)
#  condition(338)
#  conflict("charmpp",337,338)
#  root("charmpp")
#  variant_condition(322,"charmpp","backend")
#  variant_condition(331,"charmpp","smp")
#  variant_set("charmpp","backend","multicore")
#  variant_set("charmpp","smp","True")

# ==> [2023-04-12-11:06:06.456442] './build' 'charm++' 'multicore-linux-x86_64' 'gcc' 'gfortran' '-j10' '--destination=/home/mkandes/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-10.2.0/charmpp-6.10.2-g3qprv4xxcjwqxel4b5pcv42elw3w7lh' 'omp' 'cuda' '--build-shared' '--with-production'
#checking for CUDA toolkit directory
#CUDA_DIR=/cm/local/apps/cuda
#Selected Compiler: gcc
#Selected Options:  gfortran omp cuda
#OpenMP support should be built in SMP mode

declare -xr SPACK_PACKAGE='charmpp@6.10.2'
declare -xr SPACK_COMPILER='gcc@10.2.0'
declare -xr SPACK_VARIANTS='backend=multicore build-target=charm++ +cuda ~omp ~papi pmi=none +production ~pthreads +shared ~smp ~syncft ~tcp ~tracing'
declare -xr SPACK_DEPENDENCIES="^cuda@11.2.2/$(spack find --format '{hash:7}' cuda@11.2.2 % ${SPACK_COMPILER})"
declare -xr SPACK_SPEC="${SPACK_PACKAGE} % ${SPACK_COMPILER} ${SPACK_VARIANTS} ${SPACK_DEPENDENCIES}"

printenv

spack config get compilers
spack config get config  
spack config get mirrors
spack config get modules
spack config get packages
spack config get repos
spack config get upstreams

time -p spack spec --long --namespaces --types charmpp@6.10.2 % gcc@10.2.0 backend=multicore build-target=charm++ +cuda ~omp ~papi pmi=none +production ~pthreads +shared ~smp ~syncft ~tcp ~tracing "${SPACK_DEPENDENCIES}"
if [[ "${?}" -ne 0 ]]; then
  echo 'ERROR: spack concretization failed.'
  exit 1
fi

time -p spack install --jobs "${SLURM_CPUS_PER_TASK}" --fail-fast --yes-to-all charmpp@6.10.2 % gcc@10.2.0 backend=multicore build-target=charm++ +cuda ~omp ~papi pmi=none +production ~pthreads +shared ~smp ~syncft ~tcp ~tracing "${SPACK_DEPENDENCIES}"
if [[ "${?}" -ne 0 ]]; then
  echo 'ERROR: spack install failed.'
  exit 1
fi

#spack module lmod refresh --delete-tree -y

sbatch --dependency="afterok:${SLURM_JOB_ID}" 'namd@2.14.sh'

sleep 30

Currently Loaded Modules:
  1) slurm/expanse/21.08.8   2) gcc/10.2.0/i62tgso   3) cuda/11.2.2/blza2ps

 

LD_LIBRARY_PATH=/cm/local/apps/cuda/libs/current/lib64:/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx/lib64:/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/lib64:/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/lib:/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64
LS_COLORS=rs=0:di=38;5;33:ln=38;5;51:mh=00:pi=40;38;5;11:so=38;5;13:do=38;5;5:bd=48;5;232;38;5;11:cd=48;5;232;38;5;3:or=48;5;232;38;5;9:mi=01;05;37;41:su=48;5;196;38;5;15:sg=48;5;11;38;5;16:ca=48;5;196;38;5;226:tw=48;5;10;38;5;16:ow=48;5;10;38;5;21:st=48;5;21;38;5;15:ex=38;5;40:*.tar=38;5;9:*.tgz=38;5;9:*.arc=38;5;9:*.arj=38;5;9:*.taz=38;5;9:*.lha=38;5;9:*.lz4=38;5;9:*.lzh=38;5;9:*.lzma=38;5;9:*.tlz=38;5;9:*.txz=38;5;9:*.tzo=38;5;9:*.t7z=38;5;9:*.zip=38;5;9:*.z=38;5;9:*.dz=38;5;9:*.gz=38;5;9:*.lrz=38;5;9:*.lz=38;5;9:*.lzo=38;5;9:*.xz=38;5;9:*.zst=38;5;9:*.tzst=38;5;9:*.bz2=38;5;9:*.bz=38;5;9:*.tbz=38;5;9:*.tbz2=38;5;9:*.tz=38;5;9:*.deb=38;5;9:*.rpm=38;5;9:*.jar=38;5;9:*.war=38;5;9:*.ear=38;5;9:*.sar=38;5;9:*.rar=38;5;9:*.alz=38;5;9:*.ace=38;5;9:*.zoo=38;5;9:*.cpio=38;5;9:*.7z=38;5;9:*.rz=38;5;9:*.cab=38;5;9:*.wim=38;5;9:*.swm=38;5;9:*.dwm=38;5;9:*.esd=38;5;9:*.jpg=38;5;13:*.jpeg=38;5;13:*.mjpg=38;5;13:*.mjpeg=38;5;13:*.gif=38;5;13:*.bmp=38;5;13:*.pbm=38;5;13:*.pgm=38;5;13:*.ppm=38;5;13:*.tga=38;5;13:*.xbm=38;5;13:*.xpm=38;5;13:*.tif=38;5;13:*.tiff=38;5;13:*.png=38;5;13:*.svg=38;5;13:*.svgz=38;5;13:*.mng=38;5;13:*.pcx=38;5;13:*.mov=38;5;13:*.mpg=38;5;13:*.mpeg=38;5;13:*.m2v=38;5;13:*.mkv=38;5;13:*.webm=38;5;13:*.ogm=38;5;13:*.mp4=38;5;13:*.m4v=38;5;13:*.mp4v=38;5;13:*.vob=38;5;13:*.qt=38;5;13:*.nuv=38;5;13:*.wmv=38;5;13:*.asf=38;5;13:*.rm=38;5;13:*.rmvb=38;5;13:*.flc=38;5;13:*.avi=38;5;13:*.fli=38;5;13:*.flv=38;5;13:*.gl=38;5;13:*.dl=38;5;13:*.xcf=38;5;13:*.xwd=38;5;13:*.yuv=38;5;13:*.cgm=38;5;13:*.emf=38;5;13:*.ogv=38;5;13:*.ogx=38;5;13:*.aac=38;5;45:*.au=38;5;45:*.flac=38;5;45:*.m4a=38;5;45:*.mid=38;5;45:*.midi=38;5;45:*.mka=38;5;45:*.mp3=38;5;45:*.mpc=38;5;45:*.ogg=38;5;45:*.ra=38;5;45:*.wav=38;5;45:*.oga=38;5;45:*.opus=38;5;45:*.spx=38;5;45:*.xspf=38;5;45:
LOCAL_SCRATCH_DIR=/scratch/spack_gpu/job_21909574
SLURM_NODEID=0
SLURM_TASK_PID=2456848
__LMOD_REF_COUNT_PATH=/cm/local/apps/cuda/libs/current/bin:1;/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx/bin:1;/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin:1;/cm/shared/apps/spack/0.17.3/gpu/b/bin:1;/cm/shared/apps/slurm/current/sbin:1;/cm/shared/apps/slurm/current/bin:1;/home/spack_gpu/.local/bin:1;/home/spack_gpu/bin:1;/usr/local/bin:1;/usr/bin:1;/usr/local/sbin:1;/usr/sbin:1
_ModuleTable002_=fSxbImdjYy8xMC4yLjAiXT17WyJmbiJdPSIvY20vc2hhcmVkL2FwcHMvc3BhY2svMC4xNy4zL2dwdS9iL3NoYXJlL3NwYWNrL2xtb2QvbGludXgtcm9ja3k4LXg4Nl82NC9Db3JlL2djYy8xMC4yLjAvaTYydGdzby5sdWEiLFsiZnVsbE5hbWUiXT0iZ2NjLzEwLjIuMC9pNjJ0Z3NvIixbImxvYWRPcmRlciJdPTIscHJvcFQ9e30sWyJzdGFja0RlcHRoIl09MCxbInN0YXR1cyJdPSJhY3RpdmUiLFsidXNlck5hbWUiXT0iZ2NjLzEwLjIuMCIsfSxzbHVybT17WyJmbiJdPSIvY20vbG9jYWwvbW9kdWxlZmlsZXMvc2x1cm0vZXhwYW5zZS8yMS4wOC44IixbImZ1bGxOYW1lIl09InNsdXJtL2V4cGFuc2UvMjEuMDguOCIsWyJsb2FkT3JkZXIiXT0xLHByb3BUPXt9LFsic3RhY2tEZXB0
SSH_CONNECTION=198.202.100.14 58876 198.202.100.14 22
SPACK_PYTHON=/usr/bin/python3
SLURM_PRIO_PROCESS=0
SLURM_SUBMIT_DIR=/home/spack_gpu/software/namd
HISTCONTROL=ignoredups
COMPILER_MODULE=gcc/10.2.0
LMOD_FAMILY_COMPILER_VERSION=i62tgso
HOSTNAME=exp-15-57
LMOD_SYSTEM_DEFAULT_MODULES=DefaultModules
OLDPWD=/home/spack_gpu
__LMOD_REF_COUNT__LMFILES_=/cm/local/modulefiles/slurm/expanse/21.08.8:1;/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/Core/gcc/10.2.0/i62tgso.lua:1;/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/gcc/10.2.0/cuda/11.2.2/blza2ps.lua:1
SLURM_CPUS_PER_TASK=10
SPACK_DEPENDENCIES=^cuda@11.2.2/blza2ps
CUDA_MODULE=cuda/11.2.2
ENVIRONMENT=BATCH
SPACK_VERSION=0.17.3
ROCR_VISIBLE_DEVICES=0
SLURM_PROCID=0
SPACK_INSTANCE_VERSION=b
SLURM_JOB_GID=11491
SPACK_VARIANTS=backend=multicore build-target=charm++ +cuda ~omp ~papi pmi=none +production ~pthreads +shared ~smp ~syncft ~tcp ~tracing
SPACK_INSTANCE_DIR=/cm/shared/apps/spack/0.17.3/gpu/b
__LMOD_REF_COUNT_LD_LIBRARY_PATH=/cm/local/apps/cuda/libs/current/lib64:1;/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx/lib64:1;/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/lib64:1;/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/lib:1;/cm/shared/apps/slurm/current/lib64/slurm:1;/cm/shared/apps/slurm/current/lib64:1
SLURM_JOB_SCRIPT=/home/spack_gpu/software/namd/charmpp@6.10.2.sh
SLURMD_NODENAME=exp-15-57
_ModuleTable004_=bW9kdWxlZmlsZXMiLCIvY20vc2hhcmVkL21vZHVsZWZpbGVzIix9LFsic3lzdGVtQmFzZU1QQVRIIl09Ii9jbS9sb2NhbC9tb2R1bGVmaWxlczovY20vc2hhcmVkL2FwcHMvYWNjZXNzL21vZHVsZWZpbGVzOi9jbS9zaGFyZWQvYXBwcy94c2VkZS9tb2R1bGVmaWxlczovY20vc2hhcmVkL21vZHVsZWZpbGVzOi9ldGMvbW9kdWxlZmlsZXM6L3Vzci9zaGFyZS9tb2R1bGVmaWxlczovdXNyL3NoYXJlL01vZHVsZXMvbW9kdWxlZmlsZXMiLH0=
SLURM_TASKS_PER_NODE=1
S_COLORS=auto
which_declare=declare -f
SPACK_COMPILER=gcc@10.2.0
SLURM_JOB_RESERVATION=rocky8u7_testing
CC=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gcc
XDG_SESSION_ID=91618
SLURM_NNODES=1
USER=spack_gpu
SLURM_NTASKS_PER_NODE=1
__LMOD_REF_COUNT_MODULEPATH=/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/gcc/10.2.0:1;/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/Core:1;/cm/local/modulefiles:1;/cm/shared/apps/access/modulefiles:1;/cm/shared/apps/xsede/modulefiles:1;/etc/modulefiles:1;/usr/share/modulefiles:1;/usr/share/Modules/modulefiles:1;/cm/shared/modulefiles:1
__LMOD_REF_COUNT_LOADEDMODULES=slurm/expanse/21.08.8:1;gcc/10.2.0/i62tgso:1;cuda/11.2.2/blza2ps:1
SLURM_GPUS=1
PWD=/home/spack_gpu/software/namd
ENABLE_LMOD=1
SLURM_JOB_NODELIST=exp-15-57
HOME=/home/spack_gpu
SLURM_CLUSTER_NAME=expanse
CMAKE_PREFIX_PATH=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx:/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj
LMOD_COLORIZE=yes
LOCAL_TIME=20230424T124005-0700
SLURM_NODELIST=exp-15-57
SLURM_GPUS_ON_NODE=1
SSH_CLIENT=198.202.100.14 58876 22
LMOD_VERSION=8.2.4
CUDA_HOME=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx
CPATH=/cm/shared/apps/slurm/current/include
SLURM_NTASKS=1
LMOD_SETTARG_CMD=:
F77=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gfortran
SLURM_JOB_CPUS_PER_NODE=10
BASH_ENV=/usr/share/lmod/lmod/init/bash
SLURM_TOPOLOGY_ADDR=exp-15-57
SLURM_WORKING_CLUSTER=expanse:mgr1:6817:9472:109
SLURM_JOB_MD5SUM=76d63265f5454cbe135e9d01efd29c23  /home/spack_gpu/software/namd/charmpp@6.10.2.sh
SPACK_PACKAGE=charmpp@6.10.2
__LMOD_REF_COUNT_LIBRARY_PATH=/cm/shared/apps/slurm/current/lib64/slurm:1;/cm/shared/apps/slurm/current/lib64:1
SLURM_JOB_NAME=charmpp@6.10.2
TMPDIR=/scratch/spack_gpu/job_21909574
LIBRARY_PATH=/cm/shared/apps/slurm/current/lib64/slurm:/cm/shared/apps/slurm/current/lib64
SLURM_JOB_GPUS=0
__LMOD_REF_COUNT_CMAKE_PREFIX_PATH=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx:1;/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj:1
LMOD_sys=Linux
SLURM_JOBID=21909574
SYSTEM_NAME=expanse
_ModuleTable001_=X01vZHVsZVRhYmxlXz17WyJNVHZlcnNpb24iXT0zLFsiY19yZWJ1aWxkVGltZSJdPWZhbHNlLFsiY19zaG9ydFRpbWUiXT1mYWxzZSxkZXB0aFQ9e30sZmFtaWx5PXtbImNvbXBpbGVyIl09ImdjYy8xMC4yLjAiLH0sbVQ9e1siY3VkYS8xMS4yLjIiXT17WyJmbiJdPSIvY20vc2hhcmVkL2FwcHMvc3BhY2svMC4xNy4zL2dwdS9iL3NoYXJlL3NwYWNrL2xtb2QvbGludXgtcm9ja3k4LXg4Nl82NC9nY2MvMTAuMi4wL2N1ZGEvMTEuMi4yL2JsemEycHMubHVhIixbImZ1bGxOYW1lIl09ImN1ZGEvMTEuMi4yL2JsemEycHMiLFsibG9hZE9yZGVyIl09Myxwcm9wVD17fSxbInN0YWNrRGVwdGgiXT0wLFsic3RhdHVzIl09ImFjdGl2ZSIsWyJ1c2VyTmFtZSJdPSJjdWRhLzExLjIuMiIs
SLURM_CONF=/cm/shared/apps/slurm/var/etc/expanse/slurm.conf
LOADEDMODULES=slurm/expanse/21.08.8:gcc/10.2.0/i62tgso:cuda/11.2.2/blza2ps
FC=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gfortran
__LMOD_REF_COUNT_MANPATH=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/share/man:1;/cm/shared/apps/slurm/current/man:2;/usr/share/lmod/lmod/share/man:1;/usr/local/share/man:1;/usr/share/man:1;/cm/local/apps/environment-modules/current/share/man:1
_ModuleTable003_=aCJdPTAsWyJzdGF0dXMiXT0iYWN0aXZlIixbInVzZXJOYW1lIl09InNsdXJtIix9LH0sbXBhdGhBPXsiL2NtL3NoYXJlZC9hcHBzL3NwYWNrLzAuMTcuMy9ncHUvYi9zaGFyZS9zcGFjay9sbW9kL2xpbnV4LXJvY2t5OC14ODZfNjQvZ2NjLzEwLjIuMCIsIi9jbS9zaGFyZWQvYXBwcy9zcGFjay8wLjE3LjMvZ3B1L2Ivc2hhcmUvc3BhY2svbG1vZC9saW51eC1yb2NreTgteDg2XzY0L0NvcmUiLCIvY20vbG9jYWwvbW9kdWxlZmlsZXMiLCIvY20vc2hhcmVkL2FwcHMvYWNjZXNzL21vZHVsZWZpbGVzIiwiL2NtL3NoYXJlZC9hcHBzL3hzZWRlL21vZHVsZWZpbGVzIiwiL2V0Yy9tb2R1bGVmaWxlcyIsIi91c3Ivc2hhcmUvbW9kdWxlZmlsZXMiLCIvdXNyL3NoYXJlL01vZHVsZXMv
SLURM_NODE_ALIASES=(null)
SLURM_JOB_QOS=ind-gpu-shared-normal
LMOD_ROOT=/usr/share/lmod
SLURM_TOPOLOGY_ADDR_PATTERN=node
SSH_TTY=/dev/pts/1399
MAIL=/var/spool/mail/spack_gpu
SLURM_CPUS_ON_NODE=10
CXX=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/g++
LMOD_arch=x86_64
SLURM_JOB_NUM_NODES=1
__Init_Default_Modules=1
CMD_WLM_CLUSTER_NAME=expanse
SLURM_MEM_PER_NODE=95232
SPACK_ROOT=/cm/shared/apps/spack/0.17.3/gpu/b
SHELL=/bin/bash
TERM=xterm-256color
SLURM_JOB_UID=527835
_ModuleTable_Sz_=4
__LMOD_REF_COUNT_CPATH=/cm/shared/apps/slurm/current/include:1
SLURM_JOB_PARTITION=ind-gpu-shared
LMOD_FAMILY_COMPILER=gcc/10.2.0
SPACK_INSTANCE_NAME=gpu
SLURM_JOB_USER=spack_gpu
CUDA_VISIBLE_DEVICES=0
SLURM_NPROCS=1
CUDATOOLKIT_HOME=/cm/local/apps/cuda
SHLVL=2
SLURM_SUBMIT_HOST=login02
UNIX_TIME=1682365205
SLURM_JOB_ACCOUNT=use300
MANPATH=/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/share/man:/cm/shared/apps/slurm/current/man:/usr/share/lmod/lmod/share/man::/usr/local/share/man:/usr/share/man:/cm/local/apps/environment-modules/current/share/man
LMOD_PREPEND_BLOCK=normal
MODULEPATH=/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/gcc/10.2.0:/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/Core:/cm/local/modulefiles:/cm/shared/apps/access/modulefiles:/cm/shared/apps/xsede/modulefiles:/etc/modulefiles:/usr/share/modulefiles:/usr/share/Modules/modulefiles:/cm/shared/modulefiles
SLURM_GTIDS=0
LOGNAME=spack_gpu
DBUS_SESSION_BUS_ADDRESS=unix:path=/run/user/527835/bus
XDG_RUNTIME_DIR=/run/user/527835
MODULEPATH_ROOT=/usr/share/modulefiles
PATH=/cm/local/apps/cuda/libs/current/bin:/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx/bin:/cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin:/cm/shared/apps/spack/0.17.3/gpu/b/bin:/cm/shared/apps/slurm/current/sbin:/cm/shared/apps/slurm/current/bin:/home/spack_gpu/.local/bin:/home/spack_gpu/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin
SLURM_JOB_ID=21909574
_LMFILES_=/cm/local/modulefiles/slurm/expanse/21.08.8:/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/Core/gcc/10.2.0/i62tgso.lua:/cm/shared/apps/spack/0.17.3/gpu/b/share/spack/lmod/linux-rocky8-x86_64/gcc/10.2.0/cuda/11.2.2/blza2ps.lua
SCHEDULER_MODULE=slurm
MODULESHOME=/usr/share/lmod/lmod
LMOD_SETTARG_FULL_SUPPORT=no
HISTSIZE=-1
LMOD_PKG=/usr/share/lmod/lmod
SPACK_SPEC=charmpp@6.10.2 % gcc@10.2.0 backend=multicore build-target=charm++ +cuda ~omp ~papi pmi=none +production ~pthreads +shared ~smp ~syncft ~tcp ~tracing ^cuda@11.2.2/blza2ps
LMOD_CMD=/usr/share/lmod/lmod/libexec/lmod
SLURM_LOCALID=0
GPU_DEVICE_ORDINAL=0
LESSOPEN=||/usr/bin/lesspipe.sh %s
LMOD_FULL_SETTARG_SUPPORT=no
LMOD_DIR=/usr/share/lmod/lmod/libexec
BASH_FUNC_which%%=() {  ( alias;
 eval ${which_declare} ) | /usr/bin/which --tty-only --read-alias --read-functions --show-tilde --show-dot "$@"
}
BASH_FUNC_module%%=() {  eval $($LMOD_CMD bash "$@") && eval $(${LMOD_SETTARG_CMD:-:} -s sh)
}
BASH_FUNC_spack%%=() {  : this is a shell function from: /cm/shared/apps/spack/0.17.3/gpu/b/share/spack/setup-env.sh;
 : the real spack script is here: /cm/shared/apps/spack/0.17.3/gpu/b/bin/spack;
 _spack_shell_wrapper "$@";
 return $?
}
BASH_FUNC__spack_shell_wrapper%%=() {  for var in LD_LIBRARY_PATH DYLD_LIBRARY_PATH DYLD_FALLBACK_LIBRARY_PATH;
 do
 eval "if [ -n \"\${${var}-}\" ]; then export SPACK_$var=\${${var}}; fi";
 done;
 if [ -n "${ZSH_VERSION:-}" ]; then
 emulate -L sh;
 fi;
 _sp_flags="";
 while [ ! -z ${1+x} ] && [ "${1#-}" != "${1}" ]; do
 _sp_flags="$_sp_flags $1";
 shift;
 done;
 if [ -n "$_sp_flags" ] && [ "${_sp_flags#*h}" != "${_sp_flags}" ] || [ "${_sp_flags#*V}" != "${_sp_flags}" ]; then
 command spack $_sp_flags "$@";
 return;
 fi;
 _sp_subcommand="";
 if [ ! -z ${1+x} ]; then
 _sp_subcommand="$1";
 shift;
 fi;
 case $_sp_subcommand in 
 "cd")
 _sp_arg="";
 if [ -n "$1" ]; then
 _sp_arg="$1";
 shift;
 fi;
 if [ "$_sp_arg" = "-h" ] || [ "$_sp_arg" = "--help" ]; then
 command spack cd -h;
 else
 LOC="$(spack location $_sp_arg "$@")";
 if [ -d "$LOC" ]; then
 cd "$LOC";
 else
 return 1;
 fi;
 fi;
 return
 ;;
 "env")
 _sp_arg="";
 if [ -n "$1" ]; then
 _sp_arg="$1";
 shift;
 fi;
 if [ "$_sp_arg" = "-h" ] || [ "$_sp_arg" = "--help" ]; then
 command spack env -h;
 else
 case $_sp_arg in 
 activate)
 _a=" $@";
 if [ -z ${1+x} ] || [ "${_a#* --sh}" != "$_a" ] || [ "${_a#* --csh}" != "$_a" ] || [ "${_a#* -h}" != "$_a" ] || [ "${_a#* --help}" != "$_a" ]; then
 command spack env activate "$@";
 else
 stdout="$(command spack $_sp_flags env activate --sh "$@")" || return;
 eval "$stdout";
 fi
 ;;
 deactivate)
 _a=" $@";
 if [ "${_a#* --sh}" != "$_a" ] || [ "${_a#* --csh}" != "$_a" ]; then
 command spack env deactivate "$@";
 else
 if [ -n "$*" ]; then
 command spack env deactivate -h;
 else
 stdout="$(command spack $_sp_flags env deactivate --sh)" || return;
 eval "$stdout";
 fi;
 fi
 ;;
 *)
 command spack env $_sp_arg "$@"
 ;;
 esac;
 fi;
 return
 ;;
 "load" | "unload")
 _a=" $@";
 if [ "${_a#* --sh}" != "$_a" ] || [ "${_a#* --csh}" != "$_a" ] || [ "${_a#* -h}" != "$_a" ] || [ "${_a#* --list}" != "$_a" ] || [ "${_a#* --help}" != "$_a" ]; then
 command spack $_sp_flags $_sp_subcommand "$@";
 else
 stdout="$(command spack $_sp_flags $_sp_subcommand --sh "$@")" || return;
 eval "$stdout";
 fi
 ;;
 *)
 command spack $_sp_flags $_sp_subcommand "$@"
 ;;
 esac
}
BASH_FUNC_ml%%=() {  eval $($LMOD_DIR/ml_cmd "$@")
}
_=/usr/bin/printenv
compilers:
- compiler:
    spec: gcc@8.5.0
    paths:
      cc: /usr/bin/gcc
      cxx: /usr/bin/g++
      f77: /usr/bin/gfortran
      fc: /usr/bin/gfortran
    flags:
      cflags: -O2 -march=native
      cxxflags: -O2 -march=native
      fflags: -O2 -march=native
    operating_system: rocky8
    target: x86_64
    modules: []
    environment: {}
    extra_rpaths: []
- compiler:
    spec: gcc@10.2.0
    paths:
      cc: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gcc
      cxx: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/g++
      f77: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gfortran
      fc: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/gcc-10.2.0-i62tgsoexc6ya4h7urwhriiujk22nrnj/bin/gfortran
    flags:
      cflags: -O2 -march=native
      cxxflags: -O2 -march=native
      fflags: -O2 -march=native
    operating_system: rocky8
    target: x86_64
    modules: []
    environment: {}
    extra_rpaths: []
- compiler:
    spec: intel@19.1.3.304
    paths:
      cc: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/intel-19.1.3.304-vecir2bnonslbnjniwcxx6n5vfyeg4yf/bin/icc
      cxx: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/intel-19.1.3.304-vecir2bnonslbnjniwcxx6n5vfyeg4yf/bin/icpc
      f77: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/intel-19.1.3.304-vecir2bnonslbnjniwcxx6n5vfyeg4yf/bin/ifort
      fc: /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-skylake_avx512/gcc-8.5.0/intel-19.1.3.304-vecir2bnonslbnjniwcxx6n5vfyeg4yf/bin/ifort
    flags:
      cflags: -O2 -march=native
      cxxflags: -O2 -march=native
      fflags: -O2 -march=native
    operating_system: rocky8
    target: x86_64
    modules: []
    environment: {}
    extra_rpaths: []
config:
  install_tree:
    root: $spack/opt/spack
    projections:
      all: ${ARCHITECTURE}/${COMPILERNAME}-${COMPILERVER}/${PACKAGE}-${VERSION}-${HASH}
  template_dirs:
  - $spack/share/spack/templates

  # Temporary locations Spack can try to use for builds.
  #
  # Recommended options are given below.
  #
  # Builds can be faster in temporary directories on some (e.g., HPC) systems.
  # Specifying `$tempdir` will ensure use of the default temporary directory
  # (i.e., ``$TMP` or ``$TMPDIR``).
  #
  # Another option that prevents conflicts and potential permission issues is
  # to specify `$user_cache_path/stage`, which ensures each user builds in their
  # home directory.
  #
  # A more traditional path uses the value of `$spack/var/spack/stage`, which
  # builds directly inside Spack's instance without staging them in a
  # temporary space.  Problems with specifying a path inside a Spack instance
  # are that it precludes its use as a system package and its ability to be
  # pip installable.
  #
  # In any case, if the username is not already in the path, Spack will append
  # the value of `$user` in an attempt to avoid potential conflicts between
  # users in shared temporary spaces.
  #
  # The build stage can be purged with `spack clean --stage` and
  # `spack clean -a`, so it is important that the specified directory uniquely
  # identifies Spack staging to avoid accidentally wiping out non-Spack work.
  build_stage:
  - $tempdir/$user/spack-stage
  - $user_cache_path/stage
  # - $spack/var/spack/stage

  # Directory in which to run tests and store test results.
  # Tests will be stored in directories named by date/time and package
  # name/hash.
  test_stage: $user_cache_path/test
  source_cache: $spack/var/spack/cache
  misc_cache: $user_cache_path/cache
  connect_timeout: 10
  verify_ssl: true
  suppress_gpg_warnings: false
  install_missing_compilers: false
  checksum: true
  deprecated: false
  dirty: false
  build_language: C
  locks: true
  url_fetch_method: urllib
  ccache: false
  concretizer: clingo
  db_lock_timeout: 3
  package_lock_timeout: null
  shared_linking: rpath
  allow_sgid: true
  terminal_title: false
  debug: false
  build_jobs: 10
mirrors:
  spack-public: https://mirror.spack.io
modules:
  default:
    'enable:':
    - lmod
    lmod:
      core_compilers:
      - gcc@8.5.0
      hierarchy:
      - mpi
      hash_length: 0
      blacklist_implicits: true
      naming_scheme: '{name}/{version}/{hash:7}'
      projections:
        all: '{name}/{version}/{hash:7}'
      all:
        suffixes:
          +openmp: omp
          threads=openmp: omp
          +ipl64: i64
      cuda:
        environment:
          prepend_path:
            PATH: /cm/local/apps/cuda/libs/current/bin
            LD_LIBRARY_PATH: /cm/local/apps/cuda/libs/current/lib64
          set:
            CUDATOOLKIT_HOME: /cm/local/apps/cuda
      intel:
        environment:
          set:
            INTEL_LICENSE_FILE: 40000@elprado.sdsc.edu:40200@elprado.sdsc.edu
      petsc:
        suffixes:
          +complex: cmplx
      slepc:
        suffixes:
          ^petsc +complex: cmplx
      ^cuda:
        autoload: direct
      ^python:
        autoload: direct
      ^ucx:
        autoload: direct
  prefix_inspections:
    lib:
    - LD_LIBRARY_PATH
    lib64:
    - LD_LIBRARY_PATH
    bin:
    - PATH
    man:
    - MANPATH
    share/man:
    - MANPATH
    share/aclocal:
    - ACLOCAL_PATH
    lib/pkgconfig:
    - PKG_CONFIG_PATH
    lib64/pkgconfig:
    - PKG_CONFIG_PATH
    share/pkgconfig:
    - PKG_CONFIG_PATH
    ? ''
    : - CMAKE_PREFIX_PATH

  # These are configurations for the module set named "default"
packages:
  lmod:
    externals:
    - spec: lmod@8.2.4
      prefix: /usr
    buildable: false
  lustre:
    externals:
    - spec: lustre@2.15.2
      prefix: /usr
    buildable: false
  openssl:
    externals:
    - spec: openssl@1.1.1k
      prefix: /usr
    buildable: false
  rdma-core:
    externals:
    - spec: rdma-core@43.0
      prefix: /usr
    buildable: false
  slurm:
    externals:
    - spec: slurm@21.08.8
      prefix: /cm/shared/apps/slurm/21.08.8
    buildable: false
  librsvg:
    externals:
    - spec: librsvg@2.42.7
      prefix: /usr
    buildable: false
  ghostscript:
    externals:
    - spec: ghostscript@9.27
      prefix: /usr
    buildable: false
  gaussian:
    permissions:
      read: group
      group: gaussian
  vasp6:
    permissions:
      read: group
      group: vasp-6
  all:
    compiler: [gcc, intel, pgi, clang, xl, nag, fj, aocc]
    providers:
      awk: [gawk]
      blas: [openblas, amdblis]
      D: [ldc]
      daal: [intel-daal]
      elf: [elfutils]
      fftw-api: [fftw, amdfftw]
      flame: [libflame, amdlibflame]
      fuse: [libfuse]
      gl: [mesa+opengl, mesa18, opengl]
      glu: [mesa-glu, openglu]
      glx: [mesa+glx, mesa18+glx, opengl]
      golang: [gcc]
      iconv: [libiconv]
      ipp: [intel-ipp]
      java: [openjdk, jdk, ibm-java]
      jpeg: [libjpeg-turbo, libjpeg]
      lapack: [openblas, amdlibflame]
      lua-lang: [lua, lua-luajit]
      mariadb-client: [mariadb-c-client, mariadb]
      mkl: [intel-mkl]
      mpe: [mpe2]
      mpi: [openmpi, mpich]
      mysql-client: [mysql, mariadb-c-client]
      opencl: [pocl]
      onedal: [intel-oneapi-dal]
      osmesa: [mesa+osmesa, mesa18+osmesa]
      pbs: [openpbs, torque]
      pil: [py-pillow]
      pkgconfig: [pkgconf, pkg-config]
      rpc: [libtirpc]
      scalapack: [netlib-scalapack, amdscalapack]
      sycl: [hipsycl]
      szip: [libaec, libszip]
      tbb: [intel-tbb]
      unwind: [libunwind]
      uuid: [util-linux-uuid, libuuid]
      xxd: [xxd-standalone, vim]
      yacc: [bison, byacc]
      ziglang: [zig]
    permissions:
      read: world
      write: user
repos:
- $spack/var/spack/repos/sdsc
- $spack/var/spack/repos/builtin
upstreams: {}
Input spec
--------------------------------
[    ]  .charmpp@6.10.2%gcc@10.2.0+cuda~omp~papi+production~pthreads+shared~smp~syncft~tcp~tracing backend=multicore build-target=charm++ pmi=none
[    ]      ^builtin.cuda@11.2.2%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~dev arch=linux-rocky8-cascadelake
[bl  ]          ^builtin.libxml2@2.9.12%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~python arch=linux-rocky8-cascadelake
[bl  ]              ^builtin.libiconv@1.16%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native"  libs=shared,static arch=linux-rocky8-cascadelake
[bl  ]              ^builtin.xz@5.2.5%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~pic libs=shared,static arch=linux-rocky8-cascadelake
[bl  ]              ^builtin.zlib@1.2.11%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" +optimize+pic+shared arch=linux-rocky8-cascadelake

Concretized
--------------------------------
ldvm3k4  [    ]  builtin.charmpp@6.10.2%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" +cuda~omp~papi+production~pthreads+shared~smp~syncft~tcp~tracing backend=multicore build-target=charm++ pmi=none arch=linux-rocky8-cascadelake
blza2ps  [bl  ]      ^builtin.cuda@11.2.2%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~dev arch=linux-rocky8-cascadelake
2q4yola  [bl  ]          ^builtin.libxml2@2.9.12%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~python arch=linux-rocky8-cascadelake
5a3xt3s  [bl  ]              ^builtin.libiconv@1.16%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native"  libs=shared,static arch=linux-rocky8-cascadelake
5xho2dj  [bl  ]              ^builtin.xz@5.2.5%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" ~pic libs=shared,static arch=linux-rocky8-cascadelake
2c5fvip  [bl  ]              ^builtin.zlib@1.2.11%gcc@10.2.0 cflags="-O2 -march=native" cxxflags="-O2 -march=native" fflags="-O2 -march=native" +optimize+pic+shared arch=linux-rocky8-cascadelake

real 10.28
user 8.48
sys 0.85
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/libiconv-1.16-5a3xt3stjvynuygepnoy3fwkc4p524af
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/xz-5.2.5-5xho2djgxmtrybtbc7q5q2yi5juesbqu
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/zlib-1.2.11-2c5fvipdd5evacdfivwheqdtijr5om5z
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/libxml2-2.9.12-2q4yola2ylijts5vlbv353pptxgmu5xs
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/cuda-11.2.2-blza2psofa3wr2zumqrnh4je2f7ze3mx
==> Installing charmpp-6.10.2-ldvm3k4q4wfeys6rl434fpjnpt6h7aki
==> No binary for charmpp-6.10.2-ldvm3k4q4wfeys6rl434fpjnpt6h7aki found: installing from source
==> Warning: Expected user 527835 to own /scratch/spack_gpu, but it is owned by 0
==> Fetching https://mirror.spack.io/_source-cache/archive/7a/7abb4cace8aebdfbb8006eac03eb766897c009cfb919da0d0a33f74c3b4e6deb.tar.gz
==> No patches needed for charmpp
==> charmpp: Executing phase: 'install'
==> charmpp: Successfully installed charmpp-6.10.2-ldvm3k4q4wfeys6rl434fpjnpt6h7aki
  Fetch: 0.49s.  Build: 2m 58.03s.  Total: 2m 58.52s.
[+] /cm/shared/apps/spack/0.17.3/gpu/b/opt/spack/linux-rocky8-cascadelake/gcc-10.2.0/charmpp-6.10.2-ldvm3k4q4wfeys6rl434fpjnpt6h7aki
real 192.33
user 305.90
sys 410.20
Submitted batch job 21909617
